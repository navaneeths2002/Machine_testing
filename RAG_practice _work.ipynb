{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e504bf1e-e4ce-4ff1-94bc-27eb77cca154",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pymilvus) (78.1.1)\n",
      "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pymilvus) (1.74.0)\n",
      "Requirement already satisfied: protobuf>=5.27.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pymilvus) (5.29.5)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pymilvus) (1.1.1)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pymilvus) (5.11.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.26.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.184.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (4.14.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 1: INSTALLATION\n",
    "# ============================================\n",
    "# Run these in separate cells:\n",
    "\n",
    "# Install required packages\n",
    "!pip install pymilvus google-generativeai sentence-transformers pandas\n",
    "\n",
    "# ============================================\n",
    "# STEP 2: START MILVUS (LITE VERSION)\n",
    "# ============================================\n",
    "# Milvus Lite runs locally without Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d220d1-2d8f-47eb-92ef-09c56eacdf1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-1.1.1-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (2.3.2)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.2-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (1.23.5)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (1.22.1)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.2.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Using cached orjson-3.11.3-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting httpx>=0.27.0 (from chromadb)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro>=1.5.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.26.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.184.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->chromadb)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->chromadb)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27.0->chromadb)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading chromadb-1.1.1-cp39-abi3-win_amd64.whl (19.8 MB)\n",
      "   ---------------------------------------- 0.0/19.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.8/19.8 MB 12.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 5.5/19.8 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.4/19.8 MB 15.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 13.1/19.8 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 16.5/19.8 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.8/19.8 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.4 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Downloading tomli-2.3.0-py3-none-any.whl (14 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Downloading httptools-0.7.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading watchfiles-1.1.1-cp310-cp310-win_amd64.whl (287 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=f959cdfa5b09a4b0511fa7ff861aa11fc334d3f913dedcec9691c3282f0e340c\n",
      "  Stored in directory: c:\\users\\navan\\appdata\\local\\pip\\cache\\wheels\\e1\\26\\51\\d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, zipp, websockets, websocket-client, urllib3, tomli, sniffio, shellingham, pyproject_hooks, pybase64, overrides, orjson, opentelemetry-proto, mmh3, importlib-resources, httptools, h11, distro, bcrypt, backoff, uvicorn, opentelemetry-exporter-otlp-proto-common, importlib-metadata, httpcore, build, anyio, watchfiles, typer, posthog, opentelemetry-api, httpx, opentelemetry-semantic-conventions, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\n",
      "   --- ------------------------------------  3/37 [websockets]\n",
      "   ---- -----------------------------------  4/37 [websocket-client]\n",
      "  Attempting uninstall: urllib3\n",
      "   ---- -----------------------------------  4/37 [websocket-client]\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "   ---- -----------------------------------  4/37 [websocket-client]\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "   ---- -----------------------------------  4/37 [websocket-client]\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "   ---- -----------------------------------  4/37 [websocket-client]\n",
      "   ----- ----------------------------------  5/37 [urllib3]\n",
      "   ----- ----------------------------------  5/37 [urllib3]\n",
      "   -------- -------------------------------  8/37 [shellingham]\n",
      "   -------------- ------------------------- 13/37 [opentelemetry-proto]\n",
      "   ---------------- ----------------------- 15/37 [importlib-resources]\n",
      "   ---------------------- ----------------- 21/37 [uvicorn]\n",
      "   ---------------- ---------- 22/37 [opentelemetry-exporter-otlp-proto-common]\n",
      "   ------------------------- -------------- 24/37 [httpcore]\n",
      "   ---------------------------- ----------- 26/37 [anyio]\n",
      "   ------------------------------ --------- 28/37 [typer]\n",
      "   ------------------------------- -------- 29/37 [posthog]\n",
      "   -------------------------------- ------- 30/37 [opentelemetry-api]\n",
      "   ---------------------------- ---- 32/37 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 32/37 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 32/37 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ----------------------------------- ---- 33/37 [kubernetes]\n",
      "   ------------------------------------ --- 34/37 [opentelemetry-sdk]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   -------------------------------------- - 36/37 [chromadb]\n",
      "   ---------------------------------------- 37/37 [chromadb]\n",
      "\n",
      "Successfully installed anyio-4.11.0 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.1.1 distro-1.9.0 durationpy-0.10 h11-0.16.0 httpcore-1.0.9 httptools-0.7.1 httpx-0.28.1 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-34.1.0 mmh3-5.2.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 orjson-3.11.3 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 shellingham-1.5.4 sniffio-1.3.1 tomli-2.3.0 typer-0.19.2 urllib3-2.3.0 uvicorn-0.37.0 watchfiles-1.1.1 websocket-client-1.9.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb google-generativeai sentence-transformers pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b66597-81ea-4bd3-bb85-126f47acfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Navan\\anaconda3\\envs\\cvlabelme\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: IMPORT LIBRARIES\n",
    "# ============================================\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a4cdcd-da2d-4db4-b08e-8c61296eda90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChromaDB initialized!\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: INITIALIZE CHROMADB\n",
    "# ============================================\n",
    "\n",
    "# Initialize ChromaDB client (stores in memory by default)\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Or use persistent storage:\n",
    "# client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "print(\"✅ ChromaDB initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dfb9779-f511-4de1-9f18-183b9e099684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import google.generativeai as genai\n",
    "\n",
    "#genai.configure(api_key=\"AIzaSyB58xEsMAI0SW3oZiaMDMNhCeoQLyBvwV8\")\n",
    "\n",
    "# List all available models\n",
    "#print(\"Available Gemini models:\")\n",
    "#for model in genai.list_models():\n",
    "   # if 'generateContent' in model.supported_generation_methods:\n",
    "       # print(f\"  - {model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfdfe910-1a42-49da-94a1-6d726fd593f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini configured!\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: CONFIGURE GEMINI\n",
    "# ============================================\n",
    "\n",
    "# Set your Gemini API key here\n",
    "GEMINI_API_KEY = \"AIzaSyB58xEsMAI0SW3oZiaMDMNhCeoQLyBvwV8\"  # Replace with your actual key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Initialize Gemini model (using latest version)\n",
    "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "print(\"✅ Gemini configured!\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bea7171-9d42-42e2-9f1d-43a2d64dbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73bb7af1-cbed-465c-a056-1d93721074ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding model loaded!\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: LOAD EMBEDDING MODEL\n",
    "# ============================================\n",
    "\n",
    "# Load sentence transformer for creating embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"✅ Embedding model loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac0a3e57-4d81-4bf4-89f8-4feaec387436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 10 documents\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: PREPARE YOUR DATASET\n",
    "# ============================================\n",
    "\n",
    "# Example dataset - Replace with your own data\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for its simplicity and readability.\",\n",
    "    \"Machine learning is a subset of artificial intelligence that enables computers to learn from data.\",\n",
    "    \"ChromaDB is a vector database designed for AI applications and embeddings.\",\n",
    "    \"Gemini is Google's advanced large language model for various AI tasks.\",\n",
    "    \"RAG (Retrieval Augmented Generation) combines retrieval and generation for better AI responses.\",\n",
    "    \"Vector embeddings represent text as numerical arrays in high-dimensional space.\",\n",
    "    \"Jupyter notebooks are interactive coding environments popular in data science.\",\n",
    "    \"Natural language processing helps computers understand and generate human language.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to process complex data.\",\n",
    "    \"Transformers are a type of neural network architecture that revolutionized NLP.\"\n",
    "]\n",
    "\n",
    "# Load from CSV (uncomment to use):\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "# documents = df['text_column'].tolist()\n",
    "\n",
    "# Load from text file (uncomment to use):\n",
    "# with open('your_file.txt', 'r') as f:\n",
    "#     documents = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"✅ Loaded {len(documents)} documents\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "424989ab-afaa-4244-8fdf-2e0ac4d32b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Collection 'document_collection' created!\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: CREATE CHROMADB COLLECTION\n",
    "# ============================================\n",
    "\n",
    "# Create or get collection\n",
    "collection_name = \"document_collection\"\n",
    "\n",
    "# Delete if exists (for fresh start)\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create new collection\n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"description\": \"Document collection for RAG\"}\n",
    ")\n",
    "\n",
    "print(f\"✅ Collection '{collection_name}' created!\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eef22ff6-8ada-4dfc-a985-fcf7a8683320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings and adding to ChromaDB...\n",
      "✅ Added 10 documents to ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: CREATE EMBEDDINGS & ADD TO CHROMADB\n",
    "# ============================================\n",
    "\n",
    "print(\"Creating embeddings and adding to ChromaDB...\")\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = embedding_model.encode(documents).tolist()\n",
    "\n",
    "# Add to collection\n",
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    documents=documents,\n",
    "    ids=[f\"doc_{i}\" for i in range(len(documents))],\n",
    "    metadatas=[{\"index\": i, \"source\": \"dataset\"} for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(f\"✅ Added {len(documents)} documents to ChromaDB!\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ef75a57-b587-426e-95f5-64d54dab05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: RAG QUERY FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def rag_query(question: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Perform RAG: Retrieve relevant documents and generate answer with Gemini\n",
    "    \n",
    "    Args:\n",
    "        question: The question to answer\n",
    "        top_k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with question, retrieved docs, and answer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert question to embedding\n",
    "    question_embedding = embedding_model.encode([question])[0].tolist()\n",
    "    \n",
    "    # Step 2: Search ChromaDB for similar documents\n",
    "    results = collection.query(\n",
    "        query_embeddings=[question_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Step 3: Extract retrieved documents\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    distances = results['distances'][0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📚 RETRIEVED DOCUMENTS:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, (doc, dist) in enumerate(zip(retrieved_docs, distances), 1):\n",
    "        print(f\"{i}. [Score: {1-dist:.3f}] {doc}\")\n",
    "    \n",
    "    # Step 4: Create context from retrieved documents\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "    \n",
    "    # Step 5: Create prompt for Gemini\n",
    "    prompt = f\"\"\"Based on the following context, answer the question.\n",
    "If the answer cannot be found in the context, say \"I don't have enough information to answer that.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Step 6: Generate answer with Gemini\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        answer = response.text\n",
    "    except Exception as e:\n",
    "        answer = f\"Error generating response: {e}\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🤖 GEMINI'S ANSWER:\")\n",
    "    print(\"=\"*60)\n",
    "    print(answer)\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved_docs\": retrieved_docs,\n",
    "        \"answer\": answer,\n",
    "        \"scores\": [1-d for d in distances]\n",
    "    }\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38dce0ca-b400-4a9d-89ff-5e1bcba5271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 TESTING RAG SYSTEM\n",
      "\n",
      "\n",
      "❓ Question: What is ChromaDB?\n",
      "\n",
      "============================================================\n",
      "📚 RETRIEVED DOCUMENTS:\n",
      "============================================================\n",
      "1. [Score: 0.241] ChromaDB is a vector database designed for AI applications and embeddings.\n",
      "2. [Score: -0.661] Gemini is Google's advanced large language model for various AI tasks.\n",
      "3. [Score: -0.718] Natural language processing helps computers understand and generate human language.\n",
      "\n",
      "============================================================\n",
      "🤖 GEMINI'S ANSWER:\n",
      "============================================================\n",
      "ChromaDB is a vector database designed for AI applications and embeddings.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "❓ Question: Tell me about machine learning\n",
      "\n",
      "============================================================\n",
      "📚 RETRIEVED DOCUMENTS:\n",
      "============================================================\n",
      "1. [Score: 0.538] Machine learning is a subset of artificial intelligence that enables computers to learn from data.\n",
      "2. [Score: -0.015] Deep learning uses neural networks with multiple layers to process complex data.\n",
      "3. [Score: -0.157] Natural language processing helps computers understand and generate human language.\n",
      "\n",
      "============================================================\n",
      "🤖 GEMINI'S ANSWER:\n",
      "============================================================\n",
      "Machine learning is a subset of artificial intelligence that enables computers to learn from data.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "❓ Question: How does RAG work?\n",
      "\n",
      "============================================================\n",
      "📚 RETRIEVED DOCUMENTS:\n",
      "============================================================\n",
      "1. [Score: -0.258] RAG (Retrieval Augmented Generation) combines retrieval and generation for better AI responses.\n",
      "2. [Score: -0.838] Transformers are a type of neural network architecture that revolutionized NLP.\n",
      "3. [Score: -0.911] Deep learning uses neural networks with multiple layers to process complex data.\n",
      "\n",
      "============================================================\n",
      "🤖 GEMINI'S ANSWER:\n",
      "============================================================\n",
      "I don't have enough information to answer that.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "❓ Question: What is Python used for?\n",
      "\n",
      "============================================================\n",
      "📚 RETRIEVED DOCUMENTS:\n",
      "============================================================\n",
      "1. [Score: 0.561] Python is a high-level programming language known for its simplicity and readability.\n",
      "2. [Score: 0.031] Jupyter notebooks are interactive coding environments popular in data science.\n",
      "3. [Score: -0.301] Natural language processing helps computers understand and generate human language.\n",
      "\n",
      "============================================================\n",
      "🤖 GEMINI'S ANSWER:\n",
      "============================================================\n",
      "I don't have enough information to answer that.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 10: TEST THE SYSTEM\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n🚀 TESTING RAG SYSTEM\\n\")\n",
    "\n",
    "# Example queries\n",
    "test_questions = [\n",
    "    \"What is ChromaDB?\",\n",
    "    \"Tell me about machine learning\",\n",
    "    \"How does RAG work?\",\n",
    "    \"What is Python used for?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n❓ Question: {question}\")\n",
    "    result = rag_query(question, top_k=3)\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a601cf88-4257-4b0f-b560-99bc370c0504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete!\n",
      "\n",
      "💡 Usage:\n",
      "   ask('Your question here')\n",
      "\n",
      "Example:\n",
      "   ask('What are transformers in deep learning?')\n"
     ]
    }
   ],
   "source": [
    "# STEP 11: INTERACTIVE QUERY FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def ask(question: str):\n",
    "    \"\"\"Simple wrapper for asking questions\"\"\"\n",
    "    return rag_query(question, top_k=3)\n",
    "\n",
    "print(\"✅ Setup complete!\")\n",
    "print(\"\\n💡 Usage:\")\n",
    "print(\"   ask('Your question here')\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"   ask('What are transformers in deep learning?')\")\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26d4faf0-14b7-47bb-ba9f-cb9d8de082eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎉 ALL DONE! Your RAG system is ready!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 12: ADD MORE DOCUMENTS (OPTIONAL)\n",
    "# ============================================\n",
    "\n",
    "def add_documents(new_docs: List[str]):\n",
    "    \"\"\"Add new documents to the collection\"\"\"\n",
    "    \n",
    "    # Get current count\n",
    "    current_count = collection.count()\n",
    "    \n",
    "    # Create embeddings\n",
    "    new_embeddings = embedding_model.encode(new_docs).tolist()\n",
    "    \n",
    "    # Add to collection\n",
    "    collection.add(\n",
    "        embeddings=new_embeddings,\n",
    "        documents=new_docs,\n",
    "        ids=[f\"doc_{current_count + i}\" for i in range(len(new_docs))],\n",
    "        metadatas=[{\"index\": current_count + i, \"source\": \"added\"} for i in range(len(new_docs))]\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Added {len(new_docs)} new documents!\")\n",
    "    print(f\"📊 Total documents: {collection.count()}\")\n",
    "\n",
    "# Example usage:\n",
    "# add_documents([\"New document 1\", \"New document 2\"])\n",
    "\n",
    "# ============================================\n",
    "# STEP 13: SEARCH WITHOUT GEMINI (OPTIONAL)\n",
    "# ============================================\n",
    "\n",
    "def search_only(query: str, top_k: int = 5):\n",
    "    \"\"\"Search without generating an answer - just retrieval\"\"\"\n",
    "    \n",
    "    query_embedding = embedding_model.encode([query])[0].tolist()\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🔍 Search results for: '{query}'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, (doc, dist) in enumerate(zip(results['documents'][0], results['distances'][0]), 1):\n",
    "        score = 1 - dist\n",
    "        print(f\"{i}. [Score: {score:.3f}]\")\n",
    "        print(f\"   {doc}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example:\n",
    "# search_only(\"artificial intelligence\")\n",
    "\n",
    "# ============================================\n",
    "# STEP 14: VIEW COLLECTION INFO\n",
    "# ============================================\n",
    "\n",
    "def collection_info():\n",
    "    \"\"\"Display information about the collection\"\"\"\n",
    "    count = collection.count()\n",
    "    print(f\"\\n📊 Collection: {collection_name}\")\n",
    "    print(f\"📄 Total documents: {count}\")\n",
    "    print(f\"🔢 Embedding dimension: 384\")\n",
    "    \n",
    "    # Get a sample\n",
    "    if count > 0:\n",
    "        sample = collection.get(limit=3)\n",
    "        print(f\"\\n📝 Sample documents:\")\n",
    "        for i, doc in enumerate(sample['documents'], 1):\n",
    "            print(f\"   {i}. {doc[:100]}...\")\n",
    "\n",
    "# collection_info()\n",
    "\n",
    "# ============================================\n",
    "# STEP 15: CLEANUP (OPTIONAL)\n",
    "# ============================================\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Delete the collection\"\"\"\n",
    "    try:\n",
    "        client.delete_collection(name=collection_name)\n",
    "        print(\"✅ Collection deleted!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "# Uncomment to clean up:\n",
    "# cleanup()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 ALL DONE! Your RAG system is ready!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d36cb-5926-49e7-9816-a60c811f08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvlabelme]",
   "language": "python",
   "name": "conda-env-cvlabelme-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
